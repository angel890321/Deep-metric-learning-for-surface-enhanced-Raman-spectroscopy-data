{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637ab6e7",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8984c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92288fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fn = \"./data/combine_astii_astiii_filter_all_smoothing_ipm_K_pneumonia_norm.npy\"\n",
    "y_fn = \"./data/y_astii_astiii_filter_all_ipm_K_pneumonia.npy\"\n",
    "patient_fn = \"./data/patient_astii_astiii_filter_all_ipm_K_pneumonia.npy\"\n",
    "X_train_raw = np.load(X_fn,allow_pickle=True)\n",
    "y_train_raw = np.load(y_fn,allow_pickle=True)\n",
    "patient_train_raw = np.load(patient_fn,allow_pickle=True)\n",
    "\n",
    "classnames=['CR K_pneumonia','CS K_pneumonia']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa1db3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(X_train_raw, np.ndarray):\n",
    "    X_train_raw = np.array(X_train_raw, dtype=np.float32)\n",
    "elif X_train_raw.dtype != np.float32:\n",
    "    X_train_raw = X_train_raw.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7152edc6",
   "metadata": {},
   "source": [
    "## Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425f364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 09:35:40.144555: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-18 09:35:40.144591: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-18 09:35:40.145524: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "from Variant_LeNet import Variant_LeNet\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from FocalLoss import FocalLoss\n",
    "from losses import AdaptiveProxyAnchorLoss\n",
    "from imblearn.metrics import specificity_score\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    auc,\n",
    "    roc_curve,\n",
    ")\n",
    "from pytorchtools import EarlyStopping\n",
    "# Plot\n",
    "from plot import plot_CR_K_pneumonia_CS_K_pneumonia_ROC_curve, plot_heatmap,plot_tsne_interactive_html\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from config import ORDER, STRAINS\n",
    "import math\n",
    "\n",
    "# Training setting\n",
    "n_classes = 2\n",
    "epochs = 300 \n",
    "batch_size = 256\n",
    "num = 10\n",
    "num_workers = 7\n",
    "\n",
    "# metrics\n",
    "train_avg_accuracy = []\n",
    "avg_accuracy = []\n",
    "avg_roc = []\n",
    "C_total = np.zeros((n_classes, n_classes))\n",
    "C = np.zeros((n_classes, n_classes))\n",
    "C_new = np.zeros((n_classes, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a64d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(\n",
    "        self,\n",
    "        i,\n",
    "        dataloaders,\n",
    "        model,\n",
    "        model_path,\n",
    "        device,\n",
    "        n_classes,\n",
    "        alpha,\n",
    "        gpu=-1,\n",
    "    ):\n",
    "        self.i = i\n",
    "        self.dataloaders = dataloaders\n",
    "        self.device = device\n",
    "        self.net = model\n",
    "        self.net = self.net.to(self.device)\n",
    "        self.n_classes = n_classes\n",
    "        self.criterion_proxy =AdaptiveProxyAnchorLoss(nb_classes=n_classes, sz_embed=256, mrg=0.5, alpha=32,\\\n",
    "                                             nb_proxies=1, scale_margin=1).cuda()\n",
    "        self.criterion = FocalLoss(alpha=alpha, gamma=2).cuda()\n",
    "        self.get_num_labeled_class = 2\n",
    "        self.param_groups = [\n",
    "            {'params': list(set(model.parameters()).difference(set(model.embedding.parameters())))},\n",
    "            {'params': model.embedding.parameters() , 'lr':float(0.001) * 1},\n",
    "            {'params': self.criterion_proxy.mrg,'lr':float(0.001) },\n",
    "            {'params': self.criterion_proxy.proxies, 'lr':float(0.001) * 100}\n",
    "        ]\n",
    "        self.optimizer =torch.optim.AdamW(self.param_groups, lr=0.001, weight_decay = 0.001)\n",
    "        self.model_path = model_path\n",
    "\n",
    "\n",
    "    def iterate(self, epoch, phase):\n",
    "        if phase == \"train\":\n",
    "            self.net.train()\n",
    "        else:\n",
    "            self.net.eval()\n",
    "\n",
    "            \n",
    "        dataloader = self.dataloaders[phase]\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_proxy_loss = 0\n",
    "        total_crossentropy_loss = 0\n",
    "            \n",
    "        for batch_idx, (inputs, targets,patients) in enumerate(dataloader):\n",
    "            inputs, targets,patients = Variable(inputs).to(self.device), Variable(targets.long()).to(self.device), patients\n",
    "            #print(inputs.shape)\n",
    "            out,emb= self.net(inputs)\n",
    "            \n",
    "            loss1 = self.criterion(out, targets)\n",
    "            loss2 = self.criterion_proxy(emb, targets)\n",
    "            loss = loss1 + 0.5 * loss2\n",
    "            outputs = torch.argmax(out.detach(), dim=1)\n",
    "            \n",
    "            if phase == \"train\":\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                torch.nn.utils.clip_grad_value_(self.net.parameters(), 10)\n",
    "                torch.nn.utils.clip_grad_value_(self.criterion_proxy.parameters(), 10)\n",
    "\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_proxy_loss += loss2.item()\n",
    "            total_crossentropy_loss += loss1.item()\n",
    "            total += targets.size(0)\n",
    "            correct += outputs.eq(targets).cpu().sum().item()\n",
    "\n",
    "        total_loss /= (batch_idx + 1)\n",
    "        total_acc = correct / total\n",
    "\n",
    "                \n",
    "        print(\"\\nepoch %d: %s average loss: %.3f | acc: %.2f%% (%d/%d)\"\n",
    "                % (epoch + 1, phase, total_loss, 100.0 * total_acc, correct, total))\n",
    "\n",
    "        return total_loss,total_acc,out,targets\n",
    "            \n",
    "\n",
    "    def train(self, epochs):\n",
    "        best_loss = float(\"inf\")\n",
    "        best_acc = 0\n",
    "        epoch_breaks_classifer = 0\n",
    "        train_losses = []\n",
    "        train_acces = [] \n",
    "        test_losses = []\n",
    "        test_acces = [] \n",
    "\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=60)\n",
    "\n",
    "        early_stopping_classifier = EarlyStopping(patience=25, mode='acc', verbose=True)\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            train_loss,train_acc,out,targets =self.iterate(epoch, \"train\")\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            train_acces.append(train_acc)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                test_loss,test_acc,out,targets= self.iterate(epoch, \"test\")\n",
    "                    \n",
    "                test_losses.append(test_loss)\n",
    "                test_acces.append(test_acc)\n",
    "\n",
    "                if test_acc > best_acc:\n",
    "                    best_acc = test_acc\n",
    "                    checkpoint = {\n",
    "                        \"epoch\": epoch,\n",
    "                         \"train_acc\":train_acc,\n",
    "                        \"test_acc\":test_acc,\n",
    "                        \"test_loss\": test_loss,\n",
    "                        \"state_dict\": self.net.state_dict(),\n",
    "                    }\n",
    "                    print(\"best test acc found\")\n",
    "                    torch.save(checkpoint, self.model_path)\n",
    "                \n",
    "                self.scheduler.step()\n",
    "\n",
    "                early_stopping_classifier(test_acc)\n",
    "\n",
    "                epoch_breaks_classifer+= 1\n",
    "\n",
    "                if early_stopping_classifier.early_stop:\n",
    "                    break  # åœæ­¢è¨“ç·´\n",
    "        \n",
    "        if not early_stopping_classifier.early_stop:\n",
    "            epoch_breaks_classifer = epochs\n",
    "        \n",
    "\n",
    "    def test_iterate(self, phase):\n",
    "        self.net.eval()\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        y_pred_prob = []\n",
    "        \n",
    "        features_out = []\n",
    "        features_combine = []\n",
    "        targets_combine = []\n",
    "        patient_ids = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets,patients) in enumerate(dataloader):\n",
    "                inputs, targets ,patients = Variable(inputs).to('cuda'), Variable(targets.long()).to('cuda'), patients\n",
    "                out,emb = self.net(inputs)\n",
    "                outputs = torch.argmax(out.detach(), dim=1)\n",
    "                outputs_prob = nn.functional.softmax(out.detach(), dim=1)\n",
    "                y_pred.append(outputs.cpu().numpy())\n",
    "                y_pred_prob.append(outputs_prob.cpu().numpy())\n",
    "            \n",
    "                y_true.append(targets.cpu().numpy())\n",
    "                \n",
    "                targets_combine.append(targets.detach().cpu().numpy())\n",
    "                patient_ids.append(patients)\n",
    "                features_out.append(out.cpu().numpy())\n",
    "                features_combine.append(emb.detach().cpu().numpy())\n",
    "\n",
    "            targets_combine = np.concatenate(targets_combine, axis=0) \n",
    "            patient_ids = np.concatenate( patient_ids, axis=0) \n",
    "            features_out = np.concatenate(features_out, axis=0)\n",
    "            features_combine = np.concatenate(features_combine, axis=0)\n",
    "        \n",
    "        return (\n",
    "                np.hstack(y_pred),\n",
    "                np.hstack(y_true),\n",
    "                np.vstack(y_pred_prob),\n",
    "                features_out,\n",
    "                features_combine,\n",
    "                targets_combine,\n",
    "                patient_ids,\n",
    "            )\n",
    "    def test(self):\n",
    "        checkpoint = torch.load(self.model_path)\n",
    "        epoch = checkpoint[\"epoch\"]\n",
    "        train_acc = checkpoint[\"train_acc\"]\n",
    "        test_acc = checkpoint[\"test_acc\"]\n",
    "        self.net.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        print(\"load model at epoch {}, with test acc : {:.3f}\".format(epoch+1, test_acc))\n",
    "\n",
    "        \n",
    "        _, _ ,_,train_out,train_combined,train_targets,train_patient_ids = self.test_iterate(\"train\")\n",
    "        y_pred, y_true ,y_pred_prob,out,combined,targets, test_patient_ids,= self.test_iterate(\"test\")\n",
    "        \n",
    "        print(\"total\", accuracy_score(y_true, y_pred))\n",
    "        for i in range(self.n_classes):\n",
    "            idx = y_true == i\n",
    "            print(\"class\", i, accuracy_score(y_true[idx], y_pred[idx]))\n",
    "\n",
    "        return (\n",
    "            confusion_matrix(y_true, y_pred),\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            accuracy_score(y_true, y_pred),\n",
    "            y_pred_prob,\n",
    "            train_acc,\n",
    "            train_targets,\n",
    "            targets,\n",
    "            train_combined,\n",
    "            combined,\n",
    "            train_patient_ids,\n",
    "            test_patient_ids\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2e6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1: train average loss: 31.363 | acc: 70.82% (2696/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:00<03:53,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1: test average loss: 24.013 | acc: 67.38% (285/423)\n",
      "best test acc found\n",
      "\n",
      "epoch 2: train average loss: 24.701 | acc: 75.78% (2885/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/300 [00:01<02:47,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2: test average loss: 22.580 | acc: 67.38% (285/423)\n",
      "EarlyStopping counter: 1/25 (best: 0.6738)\n",
      "\n",
      "epoch 3: train average loss: 21.760 | acc: 81.95% (3120/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [00:01<02:29,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3: test average loss: 23.802 | acc: 67.38% (285/423)\n",
      "EarlyStopping counter: 2/25 (best: 0.6738)\n",
      "\n",
      "epoch 4: train average loss: 19.993 | acc: 87.47% (3330/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 4/300 [00:02<02:20,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4: test average loss: 23.728 | acc: 67.38% (285/423)\n",
      "EarlyStopping counter: 3/25 (best: 0.6738)\n",
      "\n",
      "epoch 5: train average loss: 18.651 | acc: 91.52% (3484/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 5/300 [00:02<02:15,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5: test average loss: 21.786 | acc: 84.16% (356/423)\n",
      "best test acc found\n",
      "\n",
      "epoch 6: train average loss: 18.176 | acc: 93.33% (3553/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 6/300 [00:02<02:11,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6: test average loss: 20.587 | acc: 91.96% (389/423)\n",
      "best test acc found\n",
      "\n",
      "epoch 7: train average loss: 17.678 | acc: 93.12% (3545/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 7/300 [00:03<02:08,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7: test average loss: 20.821 | acc: 95.04% (402/423)\n",
      "best test acc found\n",
      "\n",
      "epoch 8: train average loss: 17.126 | acc: 93.59% (3563/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–         | 8/300 [00:03<02:04,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8: test average loss: 20.428 | acc: 93.62% (396/423)\n",
      "EarlyStopping counter: 1/25 (best: 0.9504)\n",
      "\n",
      "epoch 9: train average loss: 16.319 | acc: 94.96% (3615/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–         | 9/300 [00:04<02:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9: test average loss: 19.861 | acc: 92.91% (393/423)\n",
      "EarlyStopping counter: 2/25 (best: 0.9504)\n",
      "\n",
      "epoch 10: train average loss: 15.827 | acc: 95.17% (3623/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–         | 10/300 [00:04<02:02,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10: test average loss: 20.994 | acc: 88.18% (373/423)\n",
      "EarlyStopping counter: 3/25 (best: 0.9504)\n",
      "\n",
      "epoch 11: train average loss: 15.604 | acc: 94.85% (3611/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 11/300 [00:04<02:01,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 11: test average loss: 20.107 | acc: 88.89% (376/423)\n",
      "EarlyStopping counter: 4/25 (best: 0.9504)\n",
      "\n",
      "epoch 12: train average loss: 14.672 | acc: 96.64% (3679/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 12/300 [00:05<02:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 12: test average loss: 19.230 | acc: 95.98% (406/423)\n",
      "best test acc found\n",
      "\n",
      "epoch 13: train average loss: 14.139 | acc: 97.03% (3694/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 13/300 [00:05<01:58,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 13: test average loss: 18.645 | acc: 95.74% (405/423)\n",
      "EarlyStopping counter: 1/25 (best: 0.9598)\n",
      "\n",
      "epoch 14: train average loss: 13.710 | acc: 96.48% (3673/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–         | 14/300 [00:06<01:56,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 14: test average loss: 19.541 | acc: 93.85% (397/423)\n",
      "EarlyStopping counter: 2/25 (best: 0.9598)\n",
      "\n",
      "epoch 15: train average loss: 13.002 | acc: 97.98% (3730/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 15/300 [00:06<01:55,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 15: test average loss: 18.918 | acc: 96.69% (409/423)\n",
      "best test acc found\n",
      "\n",
      "epoch 16: train average loss: 12.605 | acc: 97.64% (3717/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 16/300 [00:07<01:58,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 16: test average loss: 19.368 | acc: 94.80% (401/423)\n",
      "EarlyStopping counter: 1/25 (best: 0.9669)\n",
      "\n",
      "epoch 17: train average loss: 12.803 | acc: 97.98% (3730/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 17/300 [00:07<01:55,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 17: test average loss: 22.961 | acc: 78.72% (333/423)\n",
      "EarlyStopping counter: 2/25 (best: 0.9669)\n",
      "\n",
      "epoch 18: train average loss: 11.826 | acc: 98.63% (3755/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 18/300 [00:07<01:53,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 18: test average loss: 17.676 | acc: 94.80% (401/423)\n",
      "EarlyStopping counter: 3/25 (best: 0.9669)\n",
      "\n",
      "epoch 19: train average loss: 11.433 | acc: 98.82% (3762/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 19/300 [00:08<01:54,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 19: test average loss: 16.977 | acc: 97.40% (412/423)\n",
      "best test acc found\n",
      "\n",
      "epoch 20: train average loss: 11.664 | acc: 98.66% (3756/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 20/300 [00:08<01:51,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 20: test average loss: 18.439 | acc: 92.91% (393/423)\n",
      "EarlyStopping counter: 1/25 (best: 0.9740)\n",
      "\n",
      "epoch 21: train average loss: 11.348 | acc: 98.79% (3761/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 21/300 [00:09<01:51,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 21: test average loss: 20.144 | acc: 94.56% (400/423)\n",
      "EarlyStopping counter: 2/25 (best: 0.9740)\n",
      "\n",
      "epoch 22: train average loss: 10.566 | acc: 98.90% (3765/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 22/300 [00:09<01:51,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 22: test average loss: 21.527 | acc: 88.65% (375/423)\n",
      "EarlyStopping counter: 3/25 (best: 0.9740)\n",
      "\n",
      "epoch 23: train average loss: 10.155 | acc: 98.84% (3763/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 23/300 [00:09<01:51,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 23: test average loss: 16.902 | acc: 96.45% (408/423)\n",
      "EarlyStopping counter: 4/25 (best: 0.9740)\n",
      "\n",
      "epoch 24: train average loss: 9.901 | acc: 98.82% (3762/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 24/300 [00:10<01:49,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 24: test average loss: 16.857 | acc: 89.13% (377/423)\n",
      "EarlyStopping counter: 5/25 (best: 0.9740)\n",
      "\n",
      "epoch 25: train average loss: 9.577 | acc: 99.16% (3775/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 25/300 [00:10<01:50,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 25: test average loss: 16.382 | acc: 97.87% (414/423)\n",
      "best test acc found\n",
      "\n",
      "epoch 26: train average loss: 9.748 | acc: 99.21% (3777/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–Š         | 26/300 [00:10<01:47,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 26: test average loss: 18.215 | acc: 95.27% (403/423)\n",
      "EarlyStopping counter: 1/25 (best: 0.9787)\n",
      "\n",
      "epoch 27: train average loss: 9.596 | acc: 99.29% (3780/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 27/300 [00:11<01:46,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 27: test average loss: 25.290 | acc: 86.76% (367/423)\n",
      "EarlyStopping counter: 2/25 (best: 0.9787)\n",
      "\n",
      "epoch 28: train average loss: 9.185 | acc: 99.37% (3783/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 28/300 [00:11<01:51,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 28: test average loss: 16.768 | acc: 96.45% (408/423)\n",
      "EarlyStopping counter: 3/25 (best: 0.9787)\n",
      "\n",
      "epoch 29: train average loss: 9.030 | acc: 99.19% (3776/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–‰         | 29/300 [00:12<01:52,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 29: test average loss: 18.465 | acc: 96.93% (410/423)\n",
      "EarlyStopping counter: 4/25 (best: 0.9787)\n",
      "\n",
      "epoch 30: train average loss: 8.486 | acc: 99.63% (3793/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 30/300 [00:12<01:55,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 30: test average loss: 21.239 | acc: 95.98% (406/423)\n",
      "EarlyStopping counter: 5/25 (best: 0.9787)\n",
      "\n",
      "epoch 31: train average loss: 8.708 | acc: 99.42% (3785/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 31/300 [00:13<02:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 31: test average loss: 16.329 | acc: 96.93% (410/423)\n",
      "EarlyStopping counter: 6/25 (best: 0.9787)\n",
      "\n",
      "epoch 32: train average loss: 7.920 | acc: 99.84% (3801/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 32/300 [00:13<01:57,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 32: test average loss: 21.105 | acc: 95.27% (403/423)\n",
      "EarlyStopping counter: 7/25 (best: 0.9787)\n",
      "\n",
      "epoch 33: train average loss: 7.547 | acc: 99.74% (3797/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 33/300 [00:14<01:55,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 33: test average loss: 18.556 | acc: 96.93% (410/423)\n",
      "EarlyStopping counter: 8/25 (best: 0.9787)\n",
      "\n",
      "epoch 34: train average loss: 7.301 | acc: 99.71% (3796/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆâ–        | 34/300 [00:14<01:54,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 34: test average loss: 20.187 | acc: 95.74% (405/423)\n",
      "EarlyStopping counter: 9/25 (best: 0.9787)\n",
      "\n",
      "epoch 35: train average loss: 7.108 | acc: 99.84% (3801/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 35/300 [00:14<01:52,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 35: test average loss: 23.681 | acc: 95.74% (405/423)\n",
      "EarlyStopping counter: 10/25 (best: 0.9787)\n",
      "\n",
      "epoch 36: train average loss: 6.625 | acc: 99.92% (3804/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 36/300 [00:15<01:52,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 36: test average loss: 20.512 | acc: 97.40% (412/423)\n",
      "EarlyStopping counter: 11/25 (best: 0.9787)\n",
      "\n",
      "epoch 37: train average loss: 6.432 | acc: 99.92% (3804/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 37/300 [00:15<01:51,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 37: test average loss: 23.609 | acc: 96.22% (407/423)\n",
      "EarlyStopping counter: 12/25 (best: 0.9787)\n",
      "\n",
      "epoch 38: train average loss: 6.546 | acc: 99.87% (3802/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–        | 38/300 [00:16<01:47,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 38: test average loss: 20.831 | acc: 97.16% (411/423)\n",
      "EarlyStopping counter: 13/25 (best: 0.9787)\n",
      "\n",
      "epoch 39: train average loss: 6.222 | acc: 99.89% (3803/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–        | 39/300 [00:16<01:50,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 39: test average loss: 21.938 | acc: 97.16% (411/423)\n",
      "EarlyStopping counter: 14/25 (best: 0.9787)\n",
      "\n",
      "epoch 40: train average loss: 5.656 | acc: 99.92% (3804/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–        | 40/300 [00:16<01:50,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 40: test average loss: 21.680 | acc: 97.16% (411/423)\n",
      "EarlyStopping counter: 15/25 (best: 0.9787)\n",
      "\n",
      "epoch 41: train average loss: 5.343 | acc: 99.89% (3803/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 41/300 [00:17<01:47,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 41: test average loss: 20.250 | acc: 96.45% (408/423)\n",
      "EarlyStopping counter: 16/25 (best: 0.9787)\n",
      "\n",
      "epoch 42: train average loss: 4.944 | acc: 99.89% (3803/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 42/300 [00:17<01:49,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 42: test average loss: 22.927 | acc: 96.22% (407/423)\n",
      "EarlyStopping counter: 17/25 (best: 0.9787)\n",
      "\n",
      "epoch 43: train average loss: 4.789 | acc: 100.00% (3807/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 43/300 [00:18<01:47,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 43: test average loss: 22.872 | acc: 97.16% (411/423)\n",
      "EarlyStopping counter: 18/25 (best: 0.9787)\n",
      "\n",
      "epoch 44: train average loss: 4.488 | acc: 100.00% (3807/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–        | 44/300 [00:18<01:44,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 44: test average loss: 24.764 | acc: 96.93% (410/423)\n",
      "EarlyStopping counter: 19/25 (best: 0.9787)\n",
      "\n",
      "epoch 45: train average loss: 4.462 | acc: 99.97% (3806/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 45/300 [00:18<01:42,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 45: test average loss: 24.563 | acc: 97.16% (411/423)\n",
      "EarlyStopping counter: 20/25 (best: 0.9787)\n",
      "\n",
      "epoch 46: train average loss: 4.122 | acc: 100.00% (3807/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 46/300 [00:19<01:40,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 46: test average loss: 24.901 | acc: 96.69% (409/423)\n",
      "EarlyStopping counter: 21/25 (best: 0.9787)\n",
      "\n",
      "epoch 47: train average loss: 4.168 | acc: 99.89% (3803/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 47/300 [00:19<01:38,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 47: test average loss: 22.076 | acc: 97.64% (413/423)\n",
      "EarlyStopping counter: 22/25 (best: 0.9787)\n",
      "\n",
      "epoch 48: train average loss: 3.811 | acc: 99.95% (3805/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 48/300 [00:20<01:39,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 48: test average loss: 23.921 | acc: 96.93% (410/423)\n",
      "EarlyStopping counter: 23/25 (best: 0.9787)\n",
      "\n",
      "epoch 49: train average loss: 3.809 | acc: 99.95% (3805/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–‹        | 49/300 [00:20<01:38,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 49: test average loss: 24.146 | acc: 96.45% (408/423)\n",
      "EarlyStopping counter: 24/25 (best: 0.9787)\n",
      "\n",
      "epoch 50: train average loss: 3.594 | acc: 100.00% (3807/3807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–‹        | 49/300 [00:20<01:47,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 50: test average loss: 26.632 | acc: 96.45% (408/423)\n",
      "EarlyStopping counter: 25/25 (best: 0.9787)\n",
      "ğŸ”´ Early stopping triggered\n",
      "load model at epoch 25, with test acc : 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3104027/1054042983.py:175: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(self.model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0.9787234042553191\n",
      "class 0 0.9710144927536232\n",
      "class 1 0.9824561403508771\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 47\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_accuracy \u001b[38;5;241m>\u001b[39m best_test_accuracy:\n\u001b[1;32m     45\u001b[0m     best_test_accuracy \u001b[38;5;241m=\u001b[39m test_accuracy\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mplot_tsne_interactive_html\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvariant_lenet_best_test_accuracy_combined_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvariant_lenet_best_test_accuracy_combined_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrain_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_patient_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_patient_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclassnames\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     plot_heatmap(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariant_lenet_best_test_accuracy_heatmap\u001b[39m\u001b[38;5;124m\"\u001b[39m, C,class_names\u001b[38;5;241m=\u001b[39mclassnames)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_accuracy \u001b[38;5;241m<\u001b[39m low_test_accuracy:\n",
      "File \u001b[0;32m~/ä¸‹è¼‰/Deep-metric-learning-for-surface-enhanced-Raman-spectroscopy-data/plot.py:297\u001b[0m, in \u001b[0;36mplot_tsne_interactive_html\u001b[0;34m(train_save_name, test_save_name, train_feature, test_feature, train_targets, test_targets, train_patient_ids, test_patient_ids, classnames)\u001b[0m\n\u001b[1;32m    294\u001b[0m test_feature \u001b[38;5;241m=\u001b[39m test_feature\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(test_feature, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m test_feature\n\u001b[1;32m    295\u001b[0m data_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((train_feature, test_feature))\n\u001b[0;32m--> 297\u001b[0m embedding_combined \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_combined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m train_embedding \u001b[38;5;241m=\u001b[39m embedding_combined[:\u001b[38;5;28mlen\u001b[39m(train_feature)]\n\u001b[1;32m    299\u001b[0m test_embedding \u001b[38;5;241m=\u001b[39m embedding_combined[\u001b[38;5;28mlen\u001b[39m(train_feature):]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1176\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m-> 1176\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1044\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m# Degrees of freedom of the Student's t-distribution. The suggestion\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# degrees_of_freedom = n_components - 1 comes from\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# \"Learning a Parametric Embedding by Preserving Local Structure\"\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# Laurens van der Maaten, 2009.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m degrees_of_freedom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1044\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tsne\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegrees_of_freedom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_embedded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_embedded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneighbors_nn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_num_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_num_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1112\u001b[0m, in \u001b[0;36mTSNE._tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     opt_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[1;32m   1111\u001b[0m     opt_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_iter_without_progress\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_without_progress\n\u001b[0;32m-> 1112\u001b[0m     params, kl_divergence, it \u001b[38;5;241m=\u001b[39m \u001b[43m_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# Save the final number of iterations\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m it\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:403\u001b[0m, in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, max_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# only compute the error when needed\u001b[39;00m\n\u001b[1;32m    401\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m check_convergence \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m==\u001b[39m max_iter \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 403\u001b[0m error, grad \u001b[38;5;241m=\u001b[39m \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m inc \u001b[38;5;241m=\u001b[39m update \u001b[38;5;241m*\u001b[39m grad \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    406\u001b[0m dec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minvert(inc)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:284\u001b[0m, in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[1;32m    281\u001b[0m indptr \u001b[38;5;241m=\u001b[39m P\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    283\u001b[0m grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X_embedded\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 284\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[43m_barnes_hut_tsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_embedded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdegrees_of_freedom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m (degrees_of_freedom \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m/\u001b[39m degrees_of_freedom\n\u001b[1;32m    298\u001b[0m grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mravel()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets_spectrum import spectral_dataloader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "best_test_accuracy = 0\n",
    "low_test_accuracy = 1\n",
    "\n",
    "sss = StratifiedKFold(n_splits=10, shuffle=True,random_state=1)\n",
    "for fold, (train_index, test_index) in enumerate(sss.split(X_train_raw, y_train_raw)):\n",
    "    X_train, X_test = X_train_raw[train_index], X_train_raw[test_index]\n",
    "    y_train, y_test = y_train_raw[train_index], y_train_raw[test_index]\n",
    "    patient_train ,patient_test = patient_train_raw[train_index],patient_train_raw[test_index]\n",
    "\n",
    "    dl_tr = spectral_dataloader(\n",
    "                        X_train, y_train,patient_train, idxs=None, batch_size=batch_size, shuffle=True\n",
    "                    )\n",
    "    dl_test = spectral_dataloader(X_test, y_test,patient_test,idxs=None, batch_size=batch_size, shuffle=False)\n",
    "    values, counts = np.unique(np.asarray(y_test), return_counts=True)\n",
    "    dataloaders = {\"train\": dl_tr, \"test\": dl_test}\n",
    "\n",
    "    model = Variant_LeNet(in_channels=1, out_channels=n_classes)\n",
    "\n",
    "    model_path = f\"best_variant_lenet_model_{fold}.pth\"\n",
    "\n",
    "    class_counts = np.bincount(y_train)\n",
    "    num_classes = len(class_counts)\n",
    "    total_samples = len(y_train)\n",
    "\n",
    "    class_weights = []\n",
    "    for count in class_counts:\n",
    "        weight = 1 / (count / total_samples)\n",
    "        class_weights.append(weight)\n",
    "    class_weights = torch.FloatTensor(class_weights)\n",
    "    alpha = class_weights\n",
    "    solver = Solver(\n",
    "                fold,dataloaders, model, model_path, 'cuda', n_classes, alpha\n",
    "            )\n",
    "    print(fold + 1)\n",
    "    solver.train(epochs)\n",
    "    C, y_true, y_pred, test_accuracy , y_pred_prob,train_acc,train_targets,targets,train_combined,combined ,train_patient_ids, test_patient_ids= solver.test()\n",
    "    C_total += C  # å°‡æ¯æ¬¡è¿­ä»£çš„ C åŠ ç¸½åˆ° C_total\n",
    "    train_avg_accuracy.append(train_acc)\n",
    "    avg_accuracy.append(test_accuracy)\n",
    "\n",
    "    if test_accuracy > best_test_accuracy:\n",
    "\n",
    "        best_test_accuracy = test_accuracy\n",
    "            \n",
    "        plot_tsne_interactive_html(f\"variant_lenet_best_test_accuracy_combined_train\",f\"variant_lenet_best_test_accuracy_combined_test\",train_combined,combined,train_targets,targets, train_patient_ids, test_patient_ids,classnames )\n",
    "      \n",
    "        plot_heatmap(f\"variant_lenet_best_test_accuracy_heatmap\", C,class_names=classnames)\n",
    "        \n",
    "    if test_accuracy < low_test_accuracy:\n",
    "\n",
    "        low_test_accuracy = test_accuracy\n",
    "        \n",
    "        plot_tsne_interactive_html(f\"variant_lenet_low_test_accuracy_combined_train\",f\"variant_lenet_low_test_accuracy_combined_test\",train_combined,combined,train_targets,targets,train_patient_ids, test_patient_ids, classnames )\n",
    "            \n",
    "        plot_heatmap(f\"variant_lenet_low_test_accuracy_heatmap\", C,class_names=classnames)\n",
    "        \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(np.unique(y_true).shape[0]):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test == i, y_pred_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    values = [\n",
    "            v\n",
    "            for v in roc_auc.values()\n",
    "            if isinstance(v, (int, float)) and not math.isnan(v)\n",
    "    ]\n",
    "    if values:\n",
    "        auc_score = sum(values) / len(values)\n",
    "    avg_roc.append(auc_score)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        C_new[i] = np.round((C[i] / (counts[i] * num)), 2)\n",
    "\n",
    "        # Plot confusion matrix\n",
    "    sns.set_context(\"talk\", rc={\"font\": \"Helvetica\", \"font.size\": 12})\n",
    "    label = [STRAINS[i] for i in ORDER]\n",
    "    cm = 100 * C_new / C_new.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        # calculate comfusion matrix\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    sensitivity = recall_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    f1 = f1_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
    "\n",
    "    # metrices result\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Accuracy\": [np.round(accuracy_score(y_true, y_pred), 4)],\n",
    "            \"Recall\": [\n",
    "                    recall_score(y_true, y_pred, average=None, zero_division=0).round(4)\n",
    "                ],\n",
    "            \"Specificity\": [specificity_score(y_true, y_pred, average=None).round(4)],\n",
    "            \"Precision\": [\n",
    "                    precision_score(y_true, y_pred, average=None, zero_division=0).round(4)\n",
    "                ],\n",
    "            \"F1 Score\": [\n",
    "                    f1_score(y_true, y_pred, average=None, zero_division=0).round(4)\n",
    "                ],\n",
    "            }\n",
    "    )\n",
    "    print(df.transpose())\n",
    "\n",
    "    plot_CR_K_pneumonia_CS_K_pneumonia_ROC_curve(f\"variant_lenet_{fold}_roc_curve\", y_true, y_test, y_pred_prob)\n",
    "\n",
    "    plot_heatmap(f\"variant_lenet_{fold}_heatmap\", cm,class_names=classnames)\n",
    "\n",
    "plot_heatmap(f\"variant_lenet_average_heatmap\", C_total,class_names=classnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f161583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max test acc: 0.9935691318327974\n",
      "min test acc: 0.9742765273311897\n",
      "test acc: [0.9839743589743589, 0.9807692307692307, 0.9903846153846154, 0.9871794871794872, 0.9839228295819936, 0.9871382636655949, 0.977491961414791, 0.9807073954983923, 0.9742765273311897, 0.9935691318327974]\n",
      "test auc: [0.9958756812490794, 0.9976923454607944, 0.9971031570678057, 0.9925860460548928, 0.9957812189795514, 0.9956819535437761, 0.9926506856071816, 0.998076353950873, 0.9942290618526192, 0.9979283811778632]\n",
      "train mean: 0.9937559635172166\n",
      "train std: 0.003127757335232157\n",
      "mean: 0.9839413801632452\n",
      "std: 0.005571725821317866\n",
      "auc mean: 0.9957604884944438\n",
      "auc std: 0.001941929837985495\n"
     ]
    }
   ],
   "source": [
    "print(\"max test acc:\", np.max(avg_accuracy))\n",
    "print(\"min test acc:\", np.min(avg_accuracy))\n",
    "\n",
    "print(\"train mean:\", np.mean(train_avg_accuracy))\n",
    "print(\"train std:\", np.std(train_avg_accuracy))\n",
    "\n",
    "    \n",
    "print(\"mean:\", np.mean(avg_accuracy))\n",
    "print(\"std:\", np.std(avg_accuracy))\n",
    "\n",
    "    \n",
    "print(\"auc mean:\", np.mean(avg_roc))\n",
    "print(\"auc std:\", np.std(avg_roc))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
